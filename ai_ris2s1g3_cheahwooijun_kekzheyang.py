# -*- coding: utf-8 -*-
"""AI_RIS2S1G3_CHEAHWOOIJUN_KEKZHEYANG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R2O5ujMSQUzw13LxybT4-Y4ICtWgt2OP
"""

# ====================
# üì¶ Imports
# ====================
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import mean_squared_error
import joblib
import requests
from io import BytesIO
import os

# ====================
# üåê Dataset URLs
# ====================
MOVIES_URL = "https://drive.google.com/uc?export=download&id=1GOuUEu1-KgepbjTxIOkbAU8VNJ5lfEg3"
CREDITS_URL = "https://drive.google.com/uc?export=download&id=10iuK9C87fYLyDLJhqT3bpVv1A2IErmHR"
RATINGS_URL = "https://drive.google.com/uc?export=download&id=122XJoryYXvv3AUa6F_y1KiCcYdXQjEp4"

# ====================
# üì• Download function
# ====================
@st.cache_data
def download_csv(url):
    r = requests.get(url)
    return pd.read_csv(BytesIO(r.content))

# ====================
# Load datasets
# ====================
movies = download_csv(MOVIES_URL)
credits = download_csv(CREDITS_URL)
ratings = download_csv(RATINGS_URL)

# ====================
# üîß Preprocessing
# ====================
ratings_aggregated = ratings.groupby(['userId', 'movieId'])['rating'].mean().reset_index()
ratings_matrix = ratings_aggregated.pivot(index="userId", columns="movieId", values="rating").fillna(0)
user_sim = cosine_similarity(ratings_matrix)
user_sim_df = pd.DataFrame(user_sim, index=ratings_matrix.index, columns=ratings_matrix.index)

# ====================
# üíæ Save processed data for fast reload
# ====================
joblib.dump(ratings_matrix, "ratings_matrix.joblib")
joblib.dump(user_sim_df, "user_sim_df.joblib")
joblib.dump(movies, "movies.joblib")

# ====================
# üé¨ Content Similarity
# ====================
from sklearn.feature_extraction.text import TfidfVectorizer

@st.cache_data
def build_content_similarity(movies_df):
    tfidf = TfidfVectorizer(stop_words='english')
    movies_df['description'] = movies_df['description'].fillna('')
    tfidf_matrix = tfidf.fit_transform(movies_df['description'])
    return cosine_similarity(tfidf_matrix)

content_similarity = build_content_similarity(movies)

# ====================
# üìä Prediction functions
# ====================
def content_predict(user_id, movie_id):
    if movie_id not in movies['id'].values:
        return None
    idx = movies[movies['id'] == movie_id].index[0]
    sims = content_similarity[idx]
    user_ratings = ratings[ratings['userId'] == user_id]
    sim_scores = [(row['rating'], sims[movies[movies['id']==row['movieId']].index[0]])
                  for _, row in user_ratings.iterrows() if row['movieId'] in movies['id'].values]
    if not sim_scores:
        return None
    weighted_sum = sum(r*s for r,s in sim_scores)
    sim_sum = sum(s for _,s in sim_scores)
    return weighted_sum/sim_sum if sim_sum != 0 else None

def collab_predict(user_id, movie_id, top_n=5):
    if movie_id not in ratings_matrix.columns or user_id not in user_sim_df.index:
        return None
    sims = user_sim_df[user_id].drop(user_id, errors='ignore')
    top_users = sims.sort_values(ascending=False).head(top_n).index
    top_ratings = ratings_matrix.loc[top_users, movie_id]
    weights = sims.loc[top_users]
    return np.dot(top_ratings, weights)/weights.sum() if weights.sum() != 0 else None

def hybrid_predict(user_id, movie_id, alpha=0.5):
    cp = content_predict(user_id, movie_id)
    cf = collab_predict(user_id, movie_id)
    if cp is None and cf is None: return None
    if cp is None: return cf
    if cf is None: return cp
    return alpha*cp + (1-alpha)*cf

# ====================
# üñ• Streamlit App
# ====================
st.title("üé¨ Movie Recommender System")

# User ID dropdown
user_id = st.selectbox("Select User ID", sorted(ratings['userId'].unique()))
movie_id = st.selectbox("Select Movie ID", sorted(movies['id'].unique()))

# Recommendation
if st.button("Predict Rating"):
    pred = hybrid_predict(user_id, movie_id)
    if pred:
        st.success(f"Predicted rating for movie {movie_id} by user {user_id}: {pred:.2f}")
    else:
        st.warning("Not enough data to predict rating.")

# ====================
# üìä Model Evaluation
# ====================
def evaluate_model(predict_func, n_samples=300):
    test = ratings_aggregated.sample(n_samples, random_state=42)
    preds, truths = [], []
    for _, row in test.iterrows():
        pred = predict_func(row['userId'], row['movieId'])
        if pred is not None:
            preds.append(pred)
            truths.append(row['rating'])
    if not preds: return None, None
    mse = mean_squared_error(truths, preds)
    rmse = np.sqrt(mse)
    return mse, rmse

if st.checkbox("Show Evaluation Metrics"):
    mse, rmse = evaluate_model(hybrid_predict)
    st.write(f"Hybrid Model ‚Üí MSE: {mse:.4f}, RMSE: {rmse:.4f}")
