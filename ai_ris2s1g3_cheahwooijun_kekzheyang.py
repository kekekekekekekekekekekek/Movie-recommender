# -*- coding: utf-8 -*-
"""AI_RIS2S1G3_CHEAHWOOIJUN_KEKZHEYANG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R2O5ujMSQUzw13LxybT4-Y4ICtWgt2OP
"""

# ====================
# ðŸ“¦ Imports & Config
# ====================
import streamlit as st
import pandas as pd
import numpy as np
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, linear_kernel
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns
import requests
from io import StringIO

# Page config
st.set_page_config(page_title="Movie Recommender", page_icon="ðŸŽ¬", layout="wide")

# ====================
# ðŸ“¥ Load / Download Data
# ====================

MOVIES_URL = "https://raw.githubusercontent.com/yourusername/yourrepo/main/movies.csv"
CREDITS_URL = "https://raw.githubusercontent.com/yourusername/yourrepo/main/credits.csv"
RATINGS_URL = "https://raw.githubusercontent.com/yourusername/yourrepo/main/ratings.csv"

@st.cache_data
def load_csv(url):
    return pd.read_csv(url)

movies = load_csv(MOVIES_URL)
credits = load_csv(CREDITS_URL)
ratings = load_csv(RATINGS_URL)

# Aggregate duplicate ratings
ratings_aggregated = ratings.groupby(['userId', 'movieId'])['rating'].mean().reset_index()

# ====================
# ðŸ”§ Feature Engineering + Joblib Caching
# ====================

# TF-IDF content matrix
@st.cache_resource
def compute_content_matrix(movies):
    tfidf = TfidfVectorizer(stop_words='english')
    movies['overview'] = movies['overview'].fillna('')
    tfidf_matrix = tfidf.fit_transform(movies['overview'])
    content_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
    return content_sim

content_similarity = joblib.load("content_similarity.joblib") if st.secrets.get("LOAD_JOBLIB", False) else compute_content_matrix(movies)
if not st.secrets.get("LOAD_JOBLIB", False):
    joblib.dump(content_similarity, "content_similarity.joblib")

# User-user similarity matrix
@st.cache_resource
def compute_user_sim_matrix(ratings_aggregated):
    ratings_matrix = ratings_aggregated.pivot(index="userId", columns="movieId", values="rating").fillna(0)
    user_sim = cosine_similarity(ratings_matrix)
    return pd.DataFrame(user_sim, index=ratings_matrix.index, columns=ratings_matrix.index), ratings_matrix

user_sim_df, ratings_matrix = compute_user_sim_matrix(ratings_aggregated)

# ====================
# ðŸŽ¯ Prediction Functions
# ====================

def content_predict(user_id, movie_id):
    if movie_id not in movies['id'].values:
        return None
    idx = movies[movies['id'] == movie_id].index[0]
    sims = content_similarity[idx]
    user_ratings = ratings[ratings['userId'] == user_id]
    if user_ratings.empty: return None
    sim_scores = [(row['rating'], sims[movies[movies['id'] == row['movieId']].index[0]])
                  for _, row in user_ratings.iterrows() if row['movieId'] in movies['id'].values]
    if not sim_scores: return None
    weighted_sum = sum(r*s for r,s in sim_scores)
    sim_sum = sum(s for _,s in sim_scores)
    return weighted_sum/sim_sum if sim_sum != 0 else None

def collab_predict(user_id, movie_id):
    if movie_id not in ratings_matrix.columns or user_id not in user_sim_df.index:
        return None
    sims = user_sim_df[user_id].drop(user_id, errors='ignore')
    top_users = sims.sort_values(ascending=False).head(5).index
    if top_users.empty: return None
    top_ratings = ratings_matrix.loc[top_users, movie_id]
    weights = sims.loc[top_users]
    if weights.sum() == 0: return None
    return np.dot(top_ratings, weights)/weights.sum()

def hybrid_predict(user_id, movie_id, alpha=0.5):
    cp = content_predict(user_id, movie_id)
    cf = collab_predict(user_id, movie_id)
    if cp is None and cf is None: return None
    if cp is None: return cf
    if cf is None: return cp
    return alpha*cp + (1-alpha)*cf

# ====================
# ðŸ–¥ Streamlit UI
# ====================

st.title("ðŸŽ¬ Movie Recommender System")

user_ids = ratings_aggregated['userId'].unique()
movie_titles = movies['title'].tolist()

selected_user = st.selectbox("Select User ID:", user_ids)
selected_movie = st.selectbox("Select Movie:", movie_titles)

if st.button("Predict Rating"):
    movie_id = movies[movies['title'] == selected_movie]['id'].values[0]
    pred_content = content_predict(selected_user, movie_id)
    pred_collab = collab_predict(selected_user, movie_id)
    pred_hybrid = hybrid_predict(selected_user, movie_id)

    st.write(f"**Content-Based Prediction:** {pred_content:.2f}" if pred_content else "No prediction")
    st.write(f"**Collaborative Filtering Prediction:** {pred_collab:.2f}" if pred_collab else "No prediction")
    st.write(f"**Hybrid Prediction:** {pred_hybrid:.2f}" if pred_hybrid else "No prediction")

# ====================
# ðŸ“Š Evaluation
# ====================

def evaluate_model(predict_func, n_samples=300):
    test = ratings_aggregated.sample(n_samples, random_state=42)
    preds, truths = [], []
    for _, row in test.iterrows():
        pred = predict_func(row['userId'], row['movieId'])
        if pred is not None:
            preds.append(pred)
            truths.append(row['rating'])
    if not preds: return None, None
    mse = mean_squared_error(truths, preds)
    rmse = np.sqrt(mse)
    return mse, rmse

if st.checkbox("Show Evaluation"):
    mse_content, rmse_content = evaluate_model(content_predict)
    mse_collab, rmse_collab = evaluate_model(collab_predict)
    mse_hybrid, rmse_hybrid = evaluate_model(hybrid_predict)

    results_df = pd.DataFrame({
        "System": ["Content-Based", "Collaborative", "Hybrid"],
        "MSE": [mse_content, mse_collab, mse_hybrid],
        "RMSE": [rmse_content, rmse_collab, rmse_hybrid]
    })
    st.write("ðŸ“Š Evaluation Results:")
    st.dataframe(results_df)

    # Visualization
    st.bar_chart(results_df.set_index("System")["RMSE"])