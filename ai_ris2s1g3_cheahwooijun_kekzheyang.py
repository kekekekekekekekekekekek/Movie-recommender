# -*- coding: utf-8 -*-
"""AI_RIS2S1G3_CHEAHWOOIJUN_KEKZHEYANG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R2O5ujMSQUzw13LxybT4-Y4ICtWgt2OP
"""

# ====================
# üì¶ Imports & Setup
# ====================
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
from sklearn.metrics.pairwise import cosine_similarity, linear_kernel

st.set_page_config(page_title="Movie Recommender", page_icon="üé¨", layout="wide")

# ====================
# üì• Load Data
# ====================
import pandas as pd

# Movie dataset URLs (from your Drive / Cell 2)
MOVIES_URL = "https://drive.google.com/uc?export=download&id=1GOuUEu1-KgepbjTxIOkbAU8VNJ5lfEg3"
CREDITS_URL = "https://drive.google.com/uc?export=download&id=10iuK9C87fYLyDLJhqT3bpVv1A2IErmHR"
RATINGS_URL = "https://drive.google.com/uc?export=download&id=122XJoryYXvv3AUa6F_y1KiCcYdXQjEp4"


# Helper function to download CSVs
def load_csv(url):
    return pd.read_csv(url, low_memory=False)  # suppress DtypeWarning

# Load datasets
movies = load_csv(MOVIES_URL)
credits = load_csv(CREDITS_URL)
ratings = load_csv(RATINGS_URL)

# Preview data (optional, for debugging)
st.write("Movies dataset:", movies.head())
st.write("Credits dataset:", credits.head())
st.write("Ratings dataset:", ratings.head())


# ====================
# üßπ Preprocessing with Joblib
# ====================

# --- Content Similarity ---
if os.path.exists("content_similarity.pkl"):
    content_similarity = joblib.load("content_similarity.pkl")
else:
    from sklearn.feature_extraction.text import TfidfVectorizer
    tfidf = TfidfVectorizer(stop_words='english')
    movies['genres'] = movies['genres'].fillna('')
    tfidf_matrix = tfidf.fit_transform(movies['genres'])
    content_similarity = linear_kernel(tfidf_matrix, tfidf_matrix)
    joblib.dump(content_similarity, "content_similarity.pkl")

# --- Collaborative Filtering ---
if os.path.exists("ratings_matrix.pkl") and os.path.exists("user_sim_df.pkl"):
    ratings_matrix = joblib.load("ratings_matrix.pkl")
    user_sim_df = joblib.load("user_sim_df.pkl")
else:
    ratings_agg = ratings.groupby(['userId','movieId'])['rating'].mean().reset_index()
    ratings_matrix = ratings_agg.pivot(index="userId", columns="movieId", values="rating").fillna(0)
    user_sim = cosine_similarity(ratings_matrix)
    user_sim_df = pd.DataFrame(user_sim, index=ratings_matrix.index, columns=ratings_matrix.index)
    joblib.dump(ratings_matrix, "ratings_matrix.pkl")
    joblib.dump(user_sim_df, "user_sim_df.pkl")

# ====================
# üéØ Prediction Functions
# ====================
def content_predict(user_id, movie_id):
    if movie_id not in movies['id'].values:
        return None
    idx = movies[movies['id'] == movie_id].index[0]
    sims = content_similarity[idx]
    user_ratings = ratings[ratings['userId'] == user_id]
    if user_ratings.empty: return None
    sim_scores = [(row['rating'], sims[movies[movies['id'] == row['movieId']].index[0]])
                  for _, row in user_ratings.iterrows() if row['movieId'] in movies['id'].values]
    if not sim_scores: return None
    weighted_sum = sum(r*s for r,s in sim_scores)
    sim_sum = sum(s for _,s in sim_scores)
    return weighted_sum/sim_sum if sim_sum != 0 else None

def collab_predict(user_id, movie_id):
    if movie_id not in ratings_matrix.columns or user_id not in user_sim_df.index:
        return None
    sims = user_sim_df[user_id].drop(user_id, errors='ignore')
    top_users = sims.sort_values(ascending=False).head(5).index
    if top_users.empty: return None
    top_ratings = ratings_matrix.loc[top_users, movie_id]
    weights = sims.loc[top_users]
    if weights.sum() == 0: return None
    return np.dot(top_ratings, weights)/weights.sum()

def hybrid_predict(user_id, movie_id, alpha=0.5):
    cp = content_predict(user_id, movie_id)
    cf = collab_predict(user_id, movie_id)
    if cp is None and cf is None: return None
    if cp is None: return cf
    if cf is None: return cp
    return alpha*cp + (1-alpha)*cf

# ====================
# üñ• Streamlit User Interface
# ====================
st.title("üé¨ Movie Recommender System")

user_id = st.number_input("Enter User ID", min_value=1, value=1)
movie_list = movies['title'].tolist()
movie_selected = st.selectbox("Select a Movie", movie_list)

predict_type = st.radio("Prediction Type", ["Content-Based", "Collaborative", "Hybrid"])
if st.button("Predict Rating"):
    movie_id = movies[movies['title'] == movie_selected]['id'].values[0]
    if predict_type == "Content-Based":
        pred = content_predict(user_id, movie_id)
    elif predict_type == "Collaborative":
        pred = collab_predict(user_id, movie_id)
    else:
        pred = hybrid_predict(user_id, movie_id)
    if pred is not None:
        st.success(f"Predicted Rating: {pred:.2f} ‚≠ê")
    else:
        st.warning("Cannot predict rating for this selection.")

# ====================
# üìä Evaluation Section
# ====================
from sklearn.metrics import mean_squared_error

def evaluate_model(predict_func, n_samples=300):
    test = ratings.sample(n_samples, random_state=42)
    preds, truths = [], []
    for _, row in test.iterrows():
        pred = predict_func(row['userId'], row['movieId'])
        if pred is not None:
            preds.append(pred)
            truths.append(row['rating'])
    if not preds: return None, None
    mse = mean_squared_error(truths, preds)
    rmse = np.sqrt(mse)
    return mse, rmse

mse_content, rmse_content = evaluate_model(content_predict)
mse_collab, rmse_collab = evaluate_model(collab_predict)
mse_hybrid, rmse_hybrid = evaluate_model(hybrid_predict)

st.subheader("üìä Evaluation Results")
st.table({
    "System": ["Content-Based", "Collaborative", "Hybrid"],
    "MSE": [mse_content, mse_collab, mse_hybrid],
    "RMSE": [rmse_content, rmse_collab, rmse_hybrid]
})
