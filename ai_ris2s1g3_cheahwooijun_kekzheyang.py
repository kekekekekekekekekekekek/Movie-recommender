# -*- coding: utf-8 -*-
"""AI_RIS2S1G3_CHEAHWOOIJUN_KEKZHEYANG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R2O5ujMSQUzw13LxybT4-Y4ICtWgt2OP
"""

# ====================
# üì¶ Imports & Setup
# ====================
import streamlit as st
import pandas as pd
import numpy as np
import requests
import joblib
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns

st.set_page_config(page_title="üé¨ Movie Recommender", layout="wide")

# ====================
# üíæ Load / Cache Datasets
# ====================
@st.cache_data
def download_csv(url):
    df = pd.read_csv(url, low_memory=False)
    return df

MOVIES_URL = "https://drive.google.com/uc?export=download&id=1GOuUEu1-KgepbjTxIOkbAU8VNJ5lfEg3"
CREDITS_URL = "https://drive.google.com/uc?export=download&id=10iuK9C87fYLyDLJhqT3bpVv1A2IErmHR"
RATINGS_URL = "https://drive.google.com/uc?export=download&id=122XJoryYXvv3AUa6F_y1KiCcYdXQjEp4"


movies = download_csv(MOVIES_URL)
credits = download_csv(CREDITS_URL)
ratings = download_csv(RATINGS_URL)

# ====================
# üîß Preprocessing
# ====================
# Aggregate duplicate ratings
ratings_agg = ratings.groupby(['userId','movieId'])['rating'].mean().reset_index()

# Pivot for collaborative filtering
ratings_matrix = ratings_agg.pivot(index="userId", columns="movieId", values="rating").fillna(0)

# User similarity matrix
user_sim = cosine_similarity(ratings_matrix)
user_sim_df = pd.DataFrame(user_sim, index=ratings_matrix.index, columns=ratings_matrix.index)

# ====================
# üìä Content-Based Similarity
# ====================
from sklearn.feature_extraction.text import TfidfVectorizer

@st.cache_data
def compute_content_similarity(movies_df):
    tfidf = TfidfVectorizer(stop_words='english')
    movies_df['overview'] = movies_df['overview'].fillna('')
    tfidf_matrix = tfidf.fit_transform(movies_df['overview'])
    return cosine_similarity(tfidf_matrix)

content_similarity = compute_content_similarity(movies)

# ====================
# üéØ Prediction Functions
# ====================
def content_predict(user_id, movie_id):
    if movie_id not in movies['id'].values: return None
    idx = movies[movies['id'] == movie_id].index[0]
    sims = content_similarity[idx]
    user_ratings = ratings[ratings['userId'] == user_id]
    sim_scores = [(row['rating'], sims[movies[movies['id']==row['movieId']].index[0]])
                  for _, row in user_ratings.iterrows() if row['movieId'] in movies['id'].values]
    if not sim_scores: return None
    weighted_sum = sum(r*s for r,s in sim_scores)
    sim_sum = sum(s for _,s in sim_scores)
    return weighted_sum/sim_sum if sim_sum != 0 else None

def collab_predict(user_id, movie_id):
    if movie_id not in ratings_matrix.columns or user_id not in user_sim_df.index: return None
    sims = user_sim_df[user_id].drop(user_id, errors='ignore')
    top_users = sims.sort_values(ascending=False).head(5).index
    if top_users.empty: return None
    top_ratings = ratings_matrix.loc[top_users, movie_id]
    weights = sims.loc[top_users]
    if weights.sum() == 0: return None
    return np.dot(top_ratings, weights)/weights.sum()

def hybrid_predict(user_id, movie_id, alpha=0.5):
    cp = content_predict(user_id, movie_id)
    cf = collab_predict(user_id, movie_id)
    if cp is None and cf is None: return None
    if cp is None: return cf
    if cf is None: return cp
    return alpha*cp + (1-alpha)*cf

# ====================
# üñ• Streamlit UI
# ====================
st.title("üé¨ Movie Recommender System")

user_id = st.selectbox("Select User ID", ratings['userId'].unique())
movie_id = st.selectbox("Select Movie", movies['title'].values)
alpha = st.slider("Hybrid Weight (Content vs Collaborative)", 0.0, 1.0, 0.5, 0.05)

if st.button("Predict Rating"):
    pred = hybrid_predict(user_id, movies[movies['title']==movie_id]['id'].values[0], alpha)
    if pred:
        st.success(f"Predicted rating for **{movie_id}** by user {user_id}: **{pred:.2f} ‚≠ê**")
    else:
        st.warning("Not enough data to predict rating.")

# ====================
# üìä Model Evaluation
# ====================
def evaluate_model(predict_func, n_samples=300):
    test = ratings_agg.sample(n_samples, random_state=42)
    preds, truths = [], []
    for _, row in test.iterrows():
        pred = predict_func(row['userId'], row['movieId'])
        if pred is not None:
            preds.append(pred)
            truths.append(row['rating'])
    if not preds: return None, None
    mse = mean_squared_error(truths, preds)
    rmse = np.sqrt(mse)
    return mse, rmse

if st.checkbox("Show Evaluation"):
    mse_content, rmse_content = evaluate_model(content_predict)
    mse_collab, rmse_collab = evaluate_model(collab_predict)
    mse_hybrid, rmse_hybrid = evaluate_model(hybrid_predict)

    results_df = pd.DataFrame({
        "System": ["Content-Based", "Collaborative", "Hybrid"],
        "MSE": [mse_content, mse_collab, mse_hybrid],
        "RMSE": [rmse_content, rmse_collab, rmse_hybrid]
    })
    st.dataframe(results_df)

    # Visualization
    st.subheader("RMSE Comparison")
    fig, ax = plt.subplots()
    sns.barplot(x="System", y="RMSE", data=results_df, palette="viridis", ax=ax)
    st.pyplot(fig)
