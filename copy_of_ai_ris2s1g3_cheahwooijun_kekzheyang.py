# -*- coding: utf-8 -*-
"""Copy of AI_RIS2S1G3_CHEAHWOOIJUN_KEKZHEYANG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kw-731u14GMzvuEDDqnmH6iqHGayDYpx
"""

# Cell 1: Setup
# -*- coding: utf-8 -*-
"""Movie Recommender System"""

import os

# Try to get the current script directory; fallback to current working directory
try:
    BASE_DIR = os.path.dirname(__file__)
except NameError:
    BASE_DIR = os.getcwd()

DATA_PATH = os.path.join(BASE_DIR, "data")

# Example: CSVs must be placed in the /data folder:
#   data/movies_metadata.csv
#   data/credits.csv
#   data/ratings_small.csv

# Cell 2: Import libraries
import pandas as pd
import numpy as np
import ast
import random
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, linear_kernel
import gradio as gr
from sklearn.metrics import mean_squared_error
import streamlit as st

# Cell 3: Load and preprocess datasets
import requests

os.makedirs(DATA_PATH, exist_ok=True)

def download_file(url, dest_path):
    """Download a file from a URL if it doesn't exist locally."""
    if not os.path.exists(dest_path):
        st.write(f"‚¨áÔ∏è Downloading {os.path.basename(dest_path)}...")
        r = requests.get(url, stream=True)
        r.raise_for_status()
        with open(dest_path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
        st.write(f"‚úÖ Saved to {dest_path}")
# Cell 3: Load and preprocess datasets
import requests

os.makedirs(DATA_PATH, exist_ok=True)

def download_file(url, dest_path):
    """Download a file from a URL if it doesn't exist locally."""
    if not os.path.exists(dest_path):
        st.write(f"‚¨áÔ∏è Downloading {os.path.basename(dest_path)}...")
        r = requests.get(url, stream=True)
        r.raise_for_status()
        with open(dest_path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
        st.write(f"‚úÖ Saved to {dest_path}")

#datasets
MOVIES_URL = "https://drive.google.com/uc?export=download&id=1GOuUEu1-KgepbjTxIOkbAU8VNJ5lfEg3"
CREDITS_URL = "https://drive.google.com/uc?export=download&id=1cAviLW6s4O30e3RBnTHus1KdUqt1iMw9"
RATINGS_URL = "https://drive.google.com/uc?export=download&id=122XJoryYXvv3AUa6F_y1KiCcYdXQjEp4"

movies_path = os.path.join(DATA_PATH, "movies_metadata.csv")
credits_path = os.path.join(DATA_PATH, "credits.csv")
ratings_path = os.path.join(DATA_PATH, "ratings_small.csv")

# Download if missing
download_file(MOVIES_URL, movies_path)
download_file(CREDITS_URL, credits_path)
download_file(RATINGS_URL, ratings_path)

# Load datasets
movies = pd.read_csv(movies_path, low_memory=False)
credits = pd.read_csv(credits_path)
ratings = pd.read_csv(ratings_path)

# üîó Replace with your own direct download links
MOVIES_URL = "https://drive.google.com/uc?export=download&id=YOUR_MOVIES_FILE_ID"
CREDITS_URL = "https://drive.google.com/uc?export=download&id=YOUR_CREDITS_FILE_ID"
RATINGS_URL = "https://drive.google.com/uc?export=download&id=YOUR_RATINGS_FILE_ID"

movies_path = os.path.join(DATA_PATH, "movies_metadata.csv")
credits_path = os.path.join(DATA_PATH, "credits.csv")
ratings_path = os.path.join(DATA_PATH, "ratings_small.csv")

# Download if missing
download_file(MOVIES_URL, movies_path)
download_file(CREDITS_URL, credits_path)
download_file(RATINGS_URL, ratings_path)

# Load datasets
movies = pd.read_csv(movies_path, low_memory=False)
credits = pd.read_csv(credits_path)
ratings = pd.read_csv(ratings_path)

# Cell 4: Clean and prepare features
# Clean features
movies['overview'] = movies['overview'].fillna('')
movies['tagline'] = movies['tagline'].fillna('')
movies['description'] = movies['overview'] + " " + movies['tagline']

# Keep only needed columns
movies = movies[['id','title','description','genres','cast','crew']]

# Parse JSON-like fields
def parse_genres(obj):
    try:
        return [i['name'] for i in ast.literal_eval(obj)]
    except:
        return []

def parse_cast(obj):
    try:
        return [i['name'] for i in ast.literal_eval(obj)[:3]]  # top 3 actors
    except:
        return []

def parse_crew(obj):
    try:
        return [i['name'] for i in ast.literal_eval(obj) if i['job'] == 'Director']
    except:
        return []

movies['genres'] = movies['genres'].apply(parse_genres)
movies['cast'] = movies['cast'].apply(parse_cast)
movies['crew'] = movies['crew'].apply(parse_crew)

# Convert lists ‚Üí strings
movies['genres'] = movies['genres'].apply(lambda x: " ".join(x))
movies['cast'] = movies['cast'].apply(lambda x: " ".join(x))
movies['crew'] = movies['crew'].apply(lambda x: " ".join(x))

# Combine final features
movies['final_features'] = (
    movies['description'] + ' ' +
    movies['genres'] + ' ' +
    movies['cast'] + ' ' +
    movies['crew']
)

# Cell 5: TF-IDF Vectorization
# TF-IDF Vectorization
tfidf = TfidfVectorizer(stop_words='english', max_features=5000)
vectors = tfidf.fit_transform(movies['final_features'])
content_similarity = cosine_similarity(vectors)

# Cell 6: Prepare collaborative filtering data
# Prepare movies metadata for collaborative filtering
movies_cf = movies[['id', 'title']].copy()
movies_cf = movies_cf.rename(columns={'id': 'movieId'})

# Merge ratings with movie titles
ratings = ratings.merge(movies_cf, on="movieId", how="inner")

# User mapping
user_mapping = {
    1: "Bob",
    2: "Alice",
    3: "Charlie",
    4: "Diana",
    5: "Eve"
}
ratings['user_name'] = ratings['userId'].replace(user_mapping)

# Create user-item matrix
user_item_matrix = ratings.pivot_table(
    index='user_name', columns='title', values='rating'
).fillna(0)

# Compute user similarity
user_sim = cosine_similarity(user_item_matrix)
user_sim_df = pd.DataFrame(user_sim, index=user_item_matrix.index, columns=user_item_matrix.index)

# Cell 7: Recommendation functions
# Content-based recommendation function
def content_based_recommend(movie_title, top_n=10):
    if movie_title not in movies['title'].values:
        return "‚ùå Movie not found in dataset.", []

    idx = movies[movies['title'] == movie_title].index[0]

    # Compute similarity only for this movie
    cosine_scores = linear_kernel(vectors[idx], vectors).flatten()

    similar_indices = cosine_scores.argsort()[-(top_n+1):-1][::-1]
    recommendations = movies.iloc[similar_indices].title.tolist()
    scores = cosine_scores[similar_indices].tolist()

    return "Content-based recommendations", [(title, float(score)) for title, score in zip(recommendations, scores)]

# Collaborative filtering recommendation function
def collaborative_recommend(user_name, top_n=50):
    if user_name not in user_item_matrix.index:
        return {}

    # Find similar users
    sim_scores = user_sim_df[user_name].drop(user_name).sort_values(ascending=False)
    top_users = sim_scores.index[:5]

    # Average ratings of top neighbors
    neighbor_ratings = user_item_matrix.loc[top_users].mean(axis=0)

    # Remove already watched movies
    watched = user_item_matrix.loc[user_name][user_item_matrix.loc[user_name] > 0].index
    neighbor_ratings = neighbor_ratings.drop(watched, errors='ignore')

    # Get top recommendations
    top_recs = neighbor_ratings.sort_values(ascending=False).head(top_n)
    return {title: score for title, score in top_recs.items()}

# Hybrid recommendation function
def hybrid_recommend(user_name, liked_movie, alpha=0.5, top_n=10):
    if not user_name or user_name.strip() == "" or user_name == "-":
        random_id = random.randint(6, 671)
        user_name = f"User_{random_id}"
        ratings['user_name'] = ratings['userId'].replace(user_mapping)
        ratings.loc[ratings['userId'] == random_id, 'user_name'] = user_name

        # Recreate user-item matrix with new user
        global user_item_matrix, user_sim_df
        user_item_matrix = ratings.pivot_table(index='user_name', columns='title', values='rating').fillna(0)
        user_sim = cosine_similarity(user_item_matrix)
        user_sim_df = pd.DataFrame(user_sim, index=user_item_matrix.index, columns=user_item_matrix.index)

    collab_scores = collaborative_recommend(user_name, top_n=50)

    if liked_movie not in movies['title'].values:
        return user_name, [("‚ùå Movie not found", 0.0)]

    idx = movies.index[movies['title'] == liked_movie][0]
    cs = list(enumerate(content_similarity[idx]))
    cs = sorted(cs, key=lambda x: x[1], reverse=True)
    content_scores = {movies.iloc[i].title: s for i, s in cs[1:51]}

    # Merge both approaches
    all_titles = set(collab_scores.keys()) | set(content_scores.keys())
    hybrid_scores = {}
    for t in all_titles:
        c = content_scores.get(t, 0.0)
        cf = collab_scores.get(t, 0.0)
        hybrid_scores[t] = alpha * c + (1 - alpha) * cf

    ranked = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]
    return user_name, [(t, float(s)) for t, s in ranked]

# ====================
# üìä Evaluation Section
# ====================
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns

# ----- Evaluation Functions -----
def content_predict(user_id, movie_id):
    if movie_id not in movies['id'].values:
        return None
    idx = movies[movies['id'] == movie_id].index[0]
    sims = content_similarity[idx]
    user_ratings = ratings[ratings['userId'] == user_id]
    if user_ratings.empty:
        return None
    sim_scores = []
    for _, row in user_ratings.iterrows():
        if row['movieId'] in movies['id'].values:
            jdx = movies[movies['id'] == row['movieId']].index[0]
            sim_scores.append((row['rating'], sims[jdx]))
    if not sim_scores:
        return None
    weighted_sum = sum(r*s for r,s in sim_scores)
    sim_sum = sum(s for _,s in sim_scores)
    return weighted_sum/sim_sum if sim_sum != 0 else None

# Aggregate duplicate ratings by taking the mean before pivoting
ratings_aggregated = ratings.groupby(['userId', 'movieId'])['rating'].mean().reset_index()

ratings_matrix = ratings_aggregated.pivot(index="userId", columns="movieId", values="rating").fillna(0)
user_sim = cosine_similarity(ratings_matrix)
user_sim_df = pd.DataFrame(user_sim, index=ratings_matrix.index, columns=ratings_matrix.index)

def collab_predict(user_id, movie_id):
    if movie_id not in ratings_matrix.columns:
        return None
    if user_id not in user_sim_df.index: # Added check for user_id
        return None
    sims = user_sim_df[user_id].drop(user_id, errors='ignore') # Added errors='ignore'
    top_users = sims.sort_values(ascending=False).head(5).index

    # Check if top_users is empty
    if top_users.empty:
        return None

    top_ratings = ratings_matrix.loc[top_users, movie_id]
    weights = sims.loc[top_users]

    # Handle cases where weights might be all zeros
    if weights.sum() == 0:
        return None

    return np.dot(top_ratings, weights)/weights.sum()

def hybrid_predict(user_id, movie_id, alpha=0.5):
    cp = content_predict(user_id, movie_id)
    cf = collab_predict(user_id, movie_id)
    if cp is None and cf is None:
        return None
    if cp is None: return cf
    if cf is None: return cp
    return alpha*cp + (1-alpha)*cf

def evaluate_model(predict_func, n_samples=300):
    # Ensure the sampled ratings are in the aggregated dataframe
    test = ratings_aggregated.sample(n_samples, random_state=42)
    preds, truths = [], []
    for _, row in test.iterrows():
        pred = predict_func(row['userId'], row['movieId'])
        if pred is not None:
            preds.append(pred)
            truths.append(row['rating'])
    if not preds:
        return None, None
    mse = mean_squared_error(truths, preds)
    rmse = np.sqrt(mse)
    return mse, rmse

# ----- Run Evaluation -----
mse_content, rmse_content = evaluate_model(content_predict)
mse_collab, rmse_collab = evaluate_model(collab_predict)
mse_hybrid, rmse_hybrid = evaluate_model(hybrid_predict)

results_df = pd.DataFrame({
    "System": ["Content-Based", "Collaborative", "Hybrid"],
    "MSE": [mse_content, mse_collab, mse_hybrid],
    "RMSE": [rmse_content, rmse_collab, rmse_hybrid]
})

print("üìä Evaluation Results:")
print(results_df)

# ----- Visualization -----
plt.figure(figsize=(8,4))
sns.barplot(x="System", y="RMSE", data=results_df, palette="viridis")
plt.title("RMSE Comparison (Lower is Better)")
plt.show()

plt.figure(figsize=(8,4))
sns.barplot(x="System", y="MSE", data=results_df, palette="magma")
plt.title("MSE Comparison (Lower is Better)")
plt.show()

# Cell 8: Gradio UI setup with toggle
# Gradio UI setup
user_choices = ["-", "Bob", "Alice", "Charlie", "Diana", "Eve"]
movie_choices = sorted(movies['title'].unique().tolist())

def get_recommendations(recommendation_type, user_choice, movie_title, num_recs):
    if not movie_title or movie_title.strip() == "":
        return "‚ùå Please select a movie first."

    if recommendation_type == "Content-Based":
        method_name, recs = content_based_recommend(movie_title, top_n=num_recs)
        resolved_user = "Content-Based Filtering"
    else:  # Hybrid
        user_input = "" if (user_choice is None or user_choice == "-") else user_choice
        resolved_user, recs = hybrid_recommend(user_input, movie_title, alpha=0.5, top_n=num_recs)
        method_name = "Hybrid recommendations"

    # Check if we got an error message
    if isinstance(recs, str) or len(recs) == 0:
        return recs if isinstance(recs, str) else "‚ùå No recommendations found."

    # Extract scores for normalization
    scores = [s for _, s in recs]
    max_score = max(scores) if scores else 1.0

    # Normalize scores so the top one is 100%
    rows = []
    for i, (title, score) in enumerate(recs, start=1):
        norm_percentage = (score / max_score) * 100 if max_score > 0 else 0
        rows.append([f"{i}. {title}", f"{norm_percentage:.1f}%"])

    # Build HTML table
    rows_html = "".join(
        f"<tr><td style='padding:6px 12px;border-bottom:1px solid #eee;'>{movie}</td>"
        f"<td style='padding:6px 12px;text-align:center;border-bottom:1px solid #eee;'>{score}</td></tr>"
        for movie, score in rows
    )

    user_display = resolved_user if recommendation_type == "Hybrid" else "Content-Based Filtering"

    table_html = (
        f"<div style='font-weight:600;margin:6px 0;'>üé≠ {method_name} for {user_display} (based on {movie_title}):</div>"
        "<table style='width:100%;border-collapse:collapse;font-size:15px;'>"
        "<thead><tr><th style='text-align:left;padding:6px 12px;border-bottom:2px solid #ccc;'>Movie</th>"
        "<th style='text-align:center;padding:6px 12px;border-bottom:2px solid #ccc;'>Score</th></tr></thead>"
        f"<tbody>{rows_html}</tbody></table>"
    )

    return table_html

with gr.Blocks() as demo:
    gr.Markdown("## üé¨ Movie Recommender System")

    # Toggle for recommendation type
    recommendation_type = gr.Radio(
        choices=["Content-Based", "Hybrid"],
        value="Content-Based",
        label="Recommendation Type"
    )

    with gr.Row():
        user_dropdown = gr.Dropdown(
            user_choices,
            label="Select Movie Critic (for Hybrid only)",
            value="-",
            interactive=True
        )
        movie_dropdown = gr.Dropdown(
            movie_choices,
            label="Select a Movie",
            interactive=True
        )

    num_recs = gr.Slider(
        1, 20, value=10, step=1,
        label="Number of Recommendations"
    )

    output_html = gr.HTML()

    # Show/hide user dropdown based on recommendation type
    def toggle_user_dropdown(rec_type):
        return gr.Dropdown(visible=(rec_type == "Hybrid"))

    recommendation_type.change(
        fn=toggle_user_dropdown,
        inputs=recommendation_type,
        outputs=user_dropdown
    )

    gr.Button("‚ú® Get Recommendations").click(
        get_recommendations,
        [recommendation_type, user_dropdown, movie_dropdown, num_recs],
        output_html
    )

# Launch the interface
demo.launch()

# Cell 9: Streamlit UI
def run_streamlit():
    st.title("üé¨ Movie Recommender System")

    st.sidebar.header("Controls")
    rec_type = st.sidebar.radio("Recommendation Type", ["Content-Based", "Hybrid"])
    user_choice = None
    if rec_type == "Hybrid":
        user_choice = st.sidebar.selectbox("Select Movie Critic", ["-"] + ["Bob", "Alice", "Charlie", "Diana", "Eve"])
    movie_title = st.sidebar.selectbox("Select a Movie", sorted(movies['title'].unique().tolist()))
    num_recs = st.sidebar.slider("Number of Recommendations", 1, 20, 10)

    if st.sidebar.button("‚ú® Get Recommendations"):
        result = get_recommendations(rec_type, user_choice, movie_title, num_recs)

        if isinstance(result, str):
            st.error(result)
        else:
            st.markdown(result, unsafe_allow_html=True)

# Only run if launched with `streamlit run`
if __name__ == "__main__":
    import sys
    if any("streamlit" in arg for arg in sys.argv):
        run_streamlit()
